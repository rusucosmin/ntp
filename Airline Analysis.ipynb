{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "- get the distane of the edge based on longitude and latitude ✅\n",
    "- add all the information to the graph so we have an easy time calculating the measures. ✅\n",
    "- get list of graph theoretical measures to apply to airline networks:\n",
    "    - number and strength of hubs \n",
    "    - network robustness measures\n",
    "    - number of/ precense if paths\n",
    "    - diameter of the graph\n",
    "    - centrality measures\n",
    "    - spectrum of graph\n",
    "    - measure of correlation between country label\n",
    "    - how much in country/out of country ✅\n",
    "    - number of triangles in graph\n",
    "    - set weights if we have multiple fights to same place by same airline ✅\n",
    "    - get overlaping nodes functions. similarity of graph\n",
    "- get planes associated with each flight in route, so we can get number of passagers. May do later only for the biggest airlines, at end of analysis ❓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "\n",
    "Economics:\n",
    "http://www.oecd.org/daf/competition/airlinecompetition.htm\n",
    "\n",
    "Graph theoretical:\n",
    "https://beta.vu.nl/nl/Images/werkstuk-meer_tcm235-280356.pdf\n",
    "\n",
    "aircraft traffic data by main airport:\n",
    "https://datamarket.com/data/set/196g/aircraft-traffic-data-by-main-airport#!ds=196g!nto=6:ntp=b:ntq=3:ntr=1.1g.1u.7.z.a.j.v.1b.t.d.s.1n.12.p.8.b.y.e.19.17.1v.9.i.11.1f.1s.1a.1w.x.14.1l.1p.4.k.1r.g.1x.1c.f.15.q.1j.1t.l.1k.1h:nts=nf.rb&display=line\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  geopy.distance import distance #calculates distance based on coordinates\n",
    "\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash download_data.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = pd.read_csv('airports.dat', header=None, names=\n",
    "                      [\"AirportID\",\"Name\", \"City\", \"Country\", \"IATA\", \"ICAO\",\n",
    "                       \"Latitude\", \"Longitude\", \"Altitude\", \"Timezone\", \"DST\", \"TzDatabaseTimeZone\",\n",
    "                       \"Type\", \"Source\"],\n",
    "                      na_values='\\\\N')\n",
    "airlines = pd.read_csv('airlines.dat', header=None, names=\n",
    "                       [\"AirlineID\", \"Name\", \"Alias\", \"IATA\", \"ICAO\", \"Callsign\", \"Country\", \"Active\"]\n",
    "                       ,na_values='\\\\N')\n",
    "routes = pd.read_csv('routes.dat', header=None, names=\n",
    "                     ['Airline', 'AirlineID', 'SourceAirport', 'SourceAirportID', 'DestinationAirport',\n",
    "                      'DestinationAirportID', 'Codeshare', 'Stops', 'Equipment'],\n",
    "                    na_values='\\\\N')\n",
    "planes = pd.read_csv('planes.dat', header=None, names=['Name', 'IATA code', 'ICAO code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep airports in that are both in routes and airports dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_airports = set(routes.SourceAirport).union(set(routes.DestinationAirport)) \n",
    "#set(airports.IATA).intersection(set(routes.SourceAirport).union(set(routes.DestinationAirport)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(airports.IATA) - valid_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airports to fill in information for :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_airports - set(airports.IATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes = routes[routes.SourceAirport.isin(valid_airports) &  routes.DestinationAirport.isin(valid_airports)]\n",
    "airports = airports[airports.IATA.isin(valid_airports)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only keep airlines in intersection of that are both in the airline and in the routes dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_airlines = set(routes.AirlineID)#set(airlines.AirlineID).intersection(set(routes.AirlineID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(airlines.AirlineID) - valid_airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = airlines[airlines.AirlineID.isin(valid_airlines)]\n",
    "routes = routes[routes.AirlineID.isin(valid_airlines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that for each airline we have exactly one edge between a given source and destination none. This means that our graph will be unweighted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_by_airline = routes[['SourceAirport', 'DestinationAirport', 'Airline']]\n",
    "routes_by_airline.drop_duplicates().shape == routes_by_airline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMatrix = [['Altay Air Base', 'AAT', 47.7498856, 88.0858078, 'Altay', 'China', 'ZWAT'],\n",
    "             ['Baise Youjiang Airport ', 'AEB', 23.7206001, 106.9599991, 'Baise', 'China', 'ZGBS'],\n",
    "             ['Tasiilaq', 'AGM', 65.6122961, -37.6183355, 'Tasiilaq', 'Greenland', 'BGAM'],\n",
    "             ['Atmautluak Airport', 'ATT', 60.8666992, -162.272995, 'Atmautluak', 'United States', ''],\n",
    "             ['Branson Airport', 'BKG', 36.532082, -93.200544, 'Branson', 'United States', 'KBBG'],\n",
    "             ['Baoshan Yunduan Airport', 'BSD', 25.0533009, 99.1682968, 'Baoshan', 'United States', 'ZPBS'],\n",
    "             ['Laguindingan Airport', 'CGY', 8.612203, 124.456496, 'Cagayan de Oro City', 'Philippines', ''],\n",
    "             ['Chuathbaluk Airport', 'CHU', 61.579102, -159.216003, 'Chuathbaluk', 'United States', 'PACH'],\n",
    "             ['Crooked Creek Airport', 'CKD', 61.8679008, -158.1349945, 'Crooked Creek', 'United States', 'CJX'],\n",
    "             ['Desierto De Atacama Airport', 'CPO', -27.2612, -70.7791977, 'Copiapo', 'Chile', 'SCAT'],\n",
    "             ['Dandong Airport', 'DDG', 40.0247002, 124.2860031, 'Dandong', 'China', 'ZYDD'],\n",
    "             ['Hamad International Airport', 'DOH', 25.2620449, 51.6130829, 'Doha', 'Qatar', 'OTHH'],\n",
    "             ['Dongying Shengli Airport', 'DOY', 37.5085983, 118.788002, 'Dongying', 'China', 'ZSDY'],\n",
    "             ['Saertu Airport', 'DQA', 46.7463889, 125.1405556, 'Daqing Shi', 'China', 'ZYDQ'],\n",
    "             ['Førde Airport', 'FDE', 61.3911018, 5.7569399, 'Førde', 'Norway', 'ENBL'],\n",
    "             ['FMt. Fuji Shizuoka Airport', 'FSZ', 34.7960435, 138.1877518, 'Makinohara', 'Japan', 'RJNS'],\n",
    "             ['Foshan Shadi Airport', 'FUO', 23.0832996, 113.0699997, 'Foshan', 'China', 'ZGFS'],\n",
    "             ['Goulimime Airport', 'GLN', 29.0266991, -10.0502996, 'Goulimime', 'Morocco', 'GMAG'],\n",
    "             ['Gheshm Airport', 'GSM', 26.9487, 56.2687988, 'Gheshm', 'Iran', 'OIKQ']]\n",
    "             \n",
    "             \n",
    "             \n",
    "append_df = pd.DataFrame(newMatrix, columns=['Name', 'IATA', 'Latitude', 'Longitude', 'City', 'Country', 'ICAO']) \n",
    "airports.append(append_df, sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports[airports.Country == 'Japan']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Routes with Airlines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only interessted in currently active airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes = pd.merge(airlines[airlines.Active == 'Y'], routes, on='AirlineID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting whether the flight is international or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_to_country = airports.set_index('IATA').Country.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_international(x):\n",
    "    try:\n",
    "        if Airport_to_country[x.SourceAirport] == Airport_to_country[x.DestinationAirport]:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['International'] = merged_routes.apply(\n",
    "    lambda x: get_international(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset frames to create mappings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep values we are interested in\n",
    "airports_filtered = airports[['Name', 'Country', 'Longitude', 'Latitude', 'Timezone', 'IATA', 'City']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IATA airport id -> longitude latitude\n",
    "#airports_filtered.dropna(inplace=True)\n",
    "airports_filtered.set_index('IATA', inplace=True)\n",
    "\n",
    "airports_filtered.Longitude.dropna().shape == airports_filtered.Longitude.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(airports.Longitude.shape)\n",
    "print(airports_filtered.Longitude.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_mapping = airports_filtered.apply(lambda x: [x.Longitude, x.Latitude], axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Airline name -> airlineID\n",
    "airline_name_to_number = merged_routes.Name.drop_duplicates().reset_index(drop=True).to_dict()\n",
    "airline_name_to_number = {v: k for k, v in airline_name_to_number.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['AirlineNbr'] = merged_routes.Name.map(airline_name_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in Nan values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['Codeshare'] = merged_routes.Codeshare.fillna('N')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the distance between two airports:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element = airports_filtered.apply(lambda x: (x.Latitude, x.Longitude), axis=1)[0]\n",
    "element2 = airports_filtered.apply(lambda x: (x.Latitude, x.Longitude), axis=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance(element, element2).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mapping = airports_filtered.apply(lambda x: (x.Latitude, x.Longitude), axis=1).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additing it to merged_routes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(source, dest):\n",
    "    try:\n",
    "        dist = distance(distance_mapping[source], distance_mapping[dest]).km\n",
    "        return dist\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['Distance'] = merged_routes.apply(lambda x: get_distance(x.SourceAirport, x.DestinationAirport), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = ['Name', 'ICAO', 'Country', 'SourceAirport', 'DestinationAirport', 'Codeshare',\n",
    "                    'Stops', 'Equipment', 'AirlineNbr', 'International', 'Distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes[relevant_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes = merged_routes[relevant_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary analysis of the biggest airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.value_counts().head(120).plot(kind='bar', color='b')\n",
    "_ = plt.xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.value_counts().plot(kind='hist', log=True, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reasonably_big_airlines = merged_routes.Name.value_counts()[merged_routes.Name.value_counts() > 100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes = merged_routes[merged_routes.Name.isin(reasonably_big_airlines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at a total of 138 airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propotion of international to national flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.groupby('Name').International.mean().plot(kind='hist', bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean distance of flights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.groupby('Name').Distance.mean().plot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max distance of flights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.groupby('Name').Distance.max().plot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(merged_routes.groupby('Name').Distance.max(),  merged_routes.groupby('Name').Distance.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(merged_routes.groupby('Name').Distance.median(),  merged_routes.groupby('Name').International.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shortest distance of flight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.groupby('Name').Distance.min().plot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion of codeshare flights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['Codeshare'] = merged_routes.Codeshare.map(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.groupby('Name').Codeshare.mean().plot(kind='hist', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing Airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(merged_routes.SourceAirport).union(set(merged_routes.DestinationAirport)) - set(airports.IATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(merged_routes.SourceAirport).union(set(merged_routes.DestinationAirport)) - set(airports.IATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create graph of all airlines:\n",
    "\n",
    "Create graph with edge having airline associated to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest = merged_routes.AirlineNbr.value_counts().head(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_attributes = ['Country', 'Name', 'AirlineNbr', 'Distance', 'International']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_Graph = nx.from_pandas_edgelist(merged_routes, \n",
    "                                        source='SourceAirport', \n",
    "                                        target='DestinationAirport', \n",
    "                                        edge_attr=['Country', 'Name', 'AirlineNbr', 'Distance', 'International'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_edges = list(nx.get_edge_attributes(Airline_Graph, 'AirlineNbr').values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(Airline_Graph, location_mapping, 'Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw_airline_network(Airline_Graph, 'All airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_to_city = airports.set_index('IATA').City.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airport_to_name = airports.set_index('IATA').Name.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_centrality = nx.eigenvector_centrality(Airline_Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centrality = np.array(list(e_centrality.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Major Airports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_airports = {Airport_to_name[k] for  k, v in e_centrality.items() if v > np.quantile(centrality, 0.99) and k in Airport_to_city.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "nx.draw_networkx(Airline_Graph, \n",
    "                 pos=nx.get_node_attributes(Airline_Graph, 'Location'), \n",
    "                 edge_color=color_edges, edge_cmap=plt.cm.Set2, node_size=0, labels=dict(), alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at individual networks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example analysis of one graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_airline_network(airline):\n",
    "    df = merged_routes[merged_routes['Name'] == airline]\n",
    "    Airline_Graph = nx.from_pandas_edgelist(df, \n",
    "                                      source='SourceAirport', target='DestinationAirport', edge_attr=['Country'])\n",
    "    nx.set_node_attributes(Airline_Graph, location_mapping, 'Location')\n",
    "    return Airline_Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ryanair = create_airline_network('Ryanair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, U = np.linalg.eigh(nx.normalized_laplacian_matrix(Ryanair).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lufthansa = create_airline_network('Lufthansa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e, U = np.linalg.eigh(nx.normalized_laplacian_matrix(Lufthansa).todense())\n",
    "plt.plot(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Name.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Country.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.Codeshare.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Low_cost = ['Southwest Airlines', 'AirAsia', 'Ryanair','easyJet', 'WestJet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes[merged_routes.Name.isin(Low_cost)].Name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_airline_network(Airline_Graph, airline):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    centrality = nx.betweenness_centrality(Airline_Graph)\n",
    "    size = np.array(list(centrality.values()))*1000\n",
    "    nx.draw_spring(Airline_Graph, node_size=size, width=0.1)\n",
    "    plt.title(airline)\n",
    "    plt.show()\n",
    "    \n",
    "def get_spectrum_figures(Airline_Graph):\n",
    "    e, U = np.linalg.eigh(nx.normalized_laplacian_matrix(Airline_Graph).todense())\n",
    "    plt.plot(e)\n",
    "    plt.show()\n",
    "    plt.plot(nx.laplacian_spectrum(Airline_Graph))\n",
    "    plt.show()\n",
    "    plt.boxplot(nx.degree_centrality(Airline_Graph).values())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cheap in Low_cost:\n",
    "    Cheap = create_airline_network(cheap)\n",
    "    draw_airline_network(Cheap, cheap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding in external information: for relected airlines - case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delays_data = pd.read_csv('delays_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delays_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mixed_fractions(x):\n",
    "    if '%' in x:\n",
    "        return float(x[:-1])/100\n",
    "    else:\n",
    "        return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delays_data['On-time (A14)'] = Delays_data['On-time (A14)'].map(convert_mixed_fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_list = pd.read_csv('airlines_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delays_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(Airline_list.name.map(lambda x: x.lower())).intersection(set(merged_routes.Name.map(lambda x: x.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(Delays_data['On-time']).intersection(airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(Airline_list.name).intersection(airlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering the networks based on stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.approximation.clique import large_clique_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_network_stats(airline):\n",
    "    Airline_Graph = create_airline_network(airline)\n",
    "    \n",
    "    \n",
    "    components = nx.number_connected_components(Airline_Graph)\n",
    "    component_ratio = 0\n",
    "    bridges = len(list(nx.bridges(Airline_Graph)))#/ Airline_Graph.number_of_edges()\n",
    "    tree = nx.is_forest(Airline_Graph)\n",
    "    max_clique = large_clique_size(Airline_Graph)\n",
    "    bipartite = nx.is_bipartite(Airline_Graph)\n",
    "    density = nx.density(Airline_Graph)\n",
    "    #try with this \n",
    "    international_ratio = merged_routes.groupby('Name').get_group(airline).International.sum() / (Airline_Graph.size()*2)\n",
    "    \n",
    "    \n",
    "    if components > 1 :\n",
    "        print(airline,'  ' ,components)\n",
    "        \n",
    "        c = sorted(nx.connected_components(Airline_Graph), key = len, reverse=True)\n",
    "        component_ratio = len([i for t in c[1:] for i in t])/ len(c[0])\n",
    "        print(component_ratio)\n",
    "        Airline_Graph = Airline_Graph.subgraph(c[0])\n",
    "\n",
    "    diameter = nx.diameter(Airline_Graph)\n",
    "    node_connectivity = nx.node_connectivity(Airline_Graph)\n",
    "    algebraic_connectivity = nx.algebraic_connectivity(Airline_Graph)\n",
    "    clustering = nx.average_clustering(Airline_Graph)\n",
    "    \n",
    "    nb = nx.betweenness_centrality(Airline_Graph, normalized=True)\n",
    "    betweenness = np.array(list(nb.values()))\n",
    "    max_betweenness = np.max(betweenness)\n",
    "    upper_betweenness = np.quantile(betweenness, 0.75)\n",
    "    median_betweenness = np.quantile(betweenness, 0.5)\n",
    "    lower_betweenness = np.quantile(betweenness, 0.27)\n",
    "    \n",
    "    node_edge_ratio =  Airline_Graph.number_of_nodes() / Airline_Graph.number_of_edges()\n",
    "    degree_assortativity = nx.degree_assortativity_coefficient(Airline_Graph)\n",
    "    shortest_path_length = nx.average_shortest_path_length(Airline_Graph)\n",
    "    \n",
    "    c = list(greedy_modularity_communities(Airline_Graph))\n",
    "    nbr_communities = len(c)\n",
    "    \n",
    "    \n",
    "    hist = nx.degree_histogram(Airline_Graph)\n",
    "    hist_len = len(hist)\n",
    "    total = sum(hist)\n",
    "    per_large_degree = sum(hist[5:])/total\n",
    "    deadend = hist[1]/total\n",
    "    path = hist[2]/total\n",
    "    tri = sum(hist[3:])/total\n",
    "\n",
    "    return np.array([per_large_degree,\n",
    "                     hist_len,\n",
    "                     deadend,\n",
    "                     path,\n",
    "                     tri,\n",
    "                     max_clique, #0\n",
    "                     tree,       #1\n",
    "                     bipartite, #2\n",
    "                     bridges, #3\n",
    "                     diameter, #4\n",
    "                     components, #5\n",
    "                     density,\n",
    "                     component_ratio, \n",
    "                     node_connectivity, \n",
    "                     clustering, \n",
    "                     algebraic_connectivity, \n",
    "                     max_betweenness,\n",
    "                     upper_betweenness,\n",
    "                     median_betweenness,\n",
    "                     lower_betweenness,\n",
    "                     degree_assortativity, \n",
    "                     shortest_path_length, \n",
    "                     international_ratio,\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_network_stats('Lufthansa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = []\n",
    "airlines = merged_routes.Name.unique()\n",
    "for name in airlines:\n",
    "    stat = get_network_stats(name)\n",
    "    if type(stat) != None:\n",
    "        Stats.append(stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put everything into a matrix, do PCA for dimensionality reduction & cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_stats = np.array(Stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = StandardScaler().fit_transform(network_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = principalComponents[:, 0]\n",
    "y = principalComponents[:, 1]\n",
    "z = principalComponents[:, 2]\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(x, y, z, c='r', marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(principalComponents[:, 0], principalComponents[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster = AgglomerativeClustering(n_clusters=10, affinity='euclidean', linkage='ward')  \n",
    "cluster.fit_predict(principalComponents)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(principalComponents[:,0], principalComponents[:,1], c=cluster.labels_, cmap=plt.cm.tab20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = principalComponents[:, 0]\n",
    "y = principalComponents[:, 1]\n",
    "z = principalComponents[:, 2]\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(x, y, z, c=cluster.labels_, marker='o', cmap=plt.cm.tab20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "gmm = GMM(n_components=5).fit(principalComponents)\n",
    "labels = gmm.predict(principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(principalComponents[:,0], principalComponents[:,1], c=labels, cmap=plt.cm.tab20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "x = principalComponents[:, 0]\n",
    "y = principalComponents[:, 2]\n",
    "z = principalComponents[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "ax.scatter(x, y, z, c=labels, cmap=plt.cm.tab20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "plt.scatter(principalComponents[:,0], principalComponents[:,1], c= cluster.labels_, cmap=plt.cm.tab20)  \n",
    "for i, name in enumerate(airlines):\n",
    "    plt.annotate(name, xy = (principalComponents[i, 0], principalComponents[i, 1]), \n",
    "             xytext = (0, 0), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = merged_routes[~merged_routes.Name.duplicated()].Country.value_counts().head().index\n",
    "most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = list(most_common) + list(merged_routes.Country.unique())\n",
    "airline_to_countryid = merged_routes.set_index('Name').Country.to_dict()\n",
    "country_coloring = [countries.index(airline_to_countryid[i]) for i in merged_routes.Name.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = [i for i, name in enumerate(airlines) if airline_to_countryid[name] in most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(principalComponents[to_keep,0], \n",
    "            principalComponents[to_keep,1], \n",
    "            c= np.array(country_coloring)[to_keep], \n",
    "            cmap=plt.cm.Set1)  \n",
    "for i in to_keep:\n",
    "    plt.annotate(airlines[i], xy = (principalComponents[i, 0], principalComponents[i, 1]), \n",
    "             xytext = (0, 0), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One large cluster of american airways:\n",
    "\n",
    "but we have some dispersion, and then a cheap airline cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "American_Airlines = ['Us Airways', 'Delta Airlines', 'American Airlines', 'United Airlines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total of 4 clusters for chinese airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chinese_Airlines = ['Air China', 'China Eastern Airlines', 'China Southern Airlines', 'Hainan Airlines']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 clear cluster for United Arab Emirates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Emirate_Airlines = ['Fly Dubai', 'Emirates', 'Etihad Airways']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "German airlines are distributed all over, there is no clear cluster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extreme_networks = ['Era Alaska', 'TUIfly', 'Air Arabia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name in Extreme_networks:\n",
    "    Airline_Graph = create_airline_network(name)\n",
    "    draw_airline_network(Airline_Graph, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_data = pd.DataFrame(principalComponents)\n",
    "\n",
    "scatter_data['name'] = airlines\n",
    "scatter_data['labels'] = cluster.labels_\n",
    "scatter_data['country'] = scatter_data.name.map(airline_to_countryid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_data['ontime'] = scatter_data.name.map(Delays_data.set_index('On-time')['On-time (A14)'].to_dict())\n",
    "scatter_data['delay'] = scatter_data.name.map(Delays_data.set_index('On-time')['Avg. Delay'].to_dict())\n",
    "scatter_data['safety'] = scatter_data.name.map(Airline_list.set_index('name').safety_score.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = scatter_data[scatter_data.delay.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter['safety'] = scatter.safety.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter[1][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only result I can see so far:\n",
    "there is a delay line that goes from bottom left to top right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(scatter[0], \n",
    "            scatter[1], \n",
    "            c= scatter['delay'], \n",
    "            cmap=plt.cm.Spectral)  \n",
    "\n",
    "for i in scatter.index:\n",
    "    plt.annotate(scatter['name'][i], xy = (scatter[0][i], scatter[1][i]), \n",
    "             xytext = (0, 0), textcoords = 'offset points')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter[-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(Stats)[list(scatter.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "#regr.fit(scatter[[0, 1, 2, 3]], scatter['delay'])\n",
    "regr.fit(X, scatter['delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regr.score(scatter[[0, 1,2, 3]], scatter['delay'])\n",
    "regr.score(X, scatter['delay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter['pred'] = regr.predict(X)#regr.predict(scatter[[0, 1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.scatter(scatter[0], \n",
    "            scatter[1], \n",
    "            c= scatter['pred'], \n",
    "            cmap=plt.cm.Spectral)  \n",
    "\n",
    "for i in scatter.index:\n",
    "    plt.annotate(scatter['name'][i], xy = (scatter[0][i], scatter[1][i]), \n",
    "             xytext = (0, 0), textcoords = 'offset points')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(regr.coef_)), np.log(abs(regr.coef_)),)\n",
    "[regr.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the safety score using linear regression\n",
    "scatter_safety=scatter[pd.notnull(scatter['safety'])]\n",
    "X_safety = np.array(Stats)[list(scatter_safety.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_safety=linear_model.LinearRegression()\n",
    "regr_safety.fit(X_safety,scatter_safety['safety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_safety.score(X_safety,scatter_safety['safety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter['pred_safety']=regr_safety.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(regr_safety.coef_)), np.log(abs(regr_safety.coef_)),)\n",
    "[regr_safety.coef_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the on-time score using linear regression\n",
    "ontime_rig=linear_model.LinearRegression()\n",
    "ontime_rig.fit(X,scatter['ontime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontime_rig.score(X,scatter['ontime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter['pred_ontime']=ontime_rig.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(ontime_rig.coef_)), np.log(abs(ontime_rig.coef_)),)\n",
    "[ontime_rig.coef_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The determining factor in prediction is: \n",
    "                     upper_betweenness,\n",
    "                     median_betweenness,\n",
    "                     lower_betweenness,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"per_large_degree,\n",
    "                     hist_len,\n",
    "                     deadend,\n",
    "                     path,\n",
    "                     tri,\n",
    "                     max_clique, \n",
    "                     tree,       \n",
    "                     bipartite, \n",
    "                     bridges, \n",
    "                     diameter,\n",
    "                     components,\n",
    "                     density,\n",
    "                     component_ratio, \n",
    "                     node_connectivity, \n",
    "                     clustering, \n",
    "                     algebraic_connectivity, \n",
    "                     max_betweenness,\n",
    "                     upper_betweenness,\n",
    "                     median_betweenness,\n",
    "                     lower_betweenness,\n",
    "                     degree_assortativity, \n",
    "                     shortest_path_length, \n",
    "                     \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting information summarized for individual networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airlines_network_analysis(airline):\n",
    "    \n",
    "    Airline_Graph = create_airline_network(airline)\n",
    "    \n",
    "    #Highlights hubs   \n",
    "    print(\"10% biggest airports of \", airline)\n",
    "    print()\n",
    "    deg = np.array(list(Airline_Graph.degree))\n",
    "    deg_value = deg[:,1]\n",
    "    deg_value = deg_value.astype(np.float)\n",
    "    perc = np.percentile(deg_value, q=90)\n",
    "    biggest_hubs = np.array(np.where(deg_value > perc))\n",
    "\n",
    "    for i in np.nditer(biggest_hubs):\n",
    "        print(airports[airports.IATA == deg[i,0]].Name.to_string(index=False), \"has degree : \", deg[i,1])\n",
    "    \n",
    "    \n",
    "    #Diameter,robustness\n",
    "    print(\"Anlysis\")\n",
    "    print(\"Number of edges : \", Airline_Graph.number_of_edges())\n",
    "    print(\"Number of nodes\", Airline_Graph.number_of_nodes(), \"nodes\")\n",
    "    print(\"Diameter : \", nx.diameter(Airline_Graph))\n",
    "    print(\"Average distance:\", merged_routes.groupby('Name').get_group(airline).Distance.mean())\n",
    "    print(\"International Ratio: \",merged_routes.groupby('Name').get_group(airline).International.sum() / (Airline_Graph.size()*2))\n",
    "    print(\"Node connectivity\", nx.node_connectivity(Airline_Graph))\n",
    "    \n",
    "    eb = nx.edge_betweenness_centrality(Airline_Graph)\n",
    "    key, value = max(eb.items(), key = lambda p: p[1])\n",
    "    print(\"Max edge betwenness: \",value , \"from \", Airport_to_city.get(key[0]), \"to\", Airport_to_city.get(key[1]))\n",
    "    key, value = min(eb.items(), key = lambda p: p[1])\n",
    "    print(\"Min edge betwenness: \",value, \"from\", Airport_to_city.get(key[0]), \"to\", Airport_to_city.get(key[1]))\n",
    "                                                            \n",
    "    nb = nx.betweenness_centrality(Airline_Graph)\n",
    "    key, value = max(nb.items(), key= lambda p:p[1])\n",
    "    print(\"Max node betwenness: \", value, \"airport\", Airport_to_city.get(key))\n",
    "    key, value = min(nb.items(), key= lambda p:p[1])\n",
    "    print(\"Min node betwenness: \", value, \"airport\", Airport_to_city.get(key))\n",
    "    print(\"Algbraic connectivity: \", nx.algebraic_connectivity(Airline_Graph))\n",
    "    \n",
    "    #Plot network\n",
    "    plt.figure(figsize=[7,9])\n",
    "    plt.subplot(211)\n",
    "    plt.title('Degree Distribution')\n",
    "    plt.hist(deg_value, bins=50)\n",
    "    \n",
    "    plt.subplot(212)\n",
    "    plt.title('Distances distribution')\n",
    "    merged_routes.groupby('Name').get_group(airline).Distance.hist(bins=30)\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    draw_airline_network(Airline_Graph, airline)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_network_analysis('Ryanair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines_network_analysis('American Airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#High cooperation probability based on common bottlenecks \n",
    "def find_helper(airline):\n",
    "    Airline_Graph = create_airline_network(airline)\n",
    "    #bottlenecks\n",
    "    eb = nx.edge_betweenness_centrality(Airline_Graph)\n",
    "    #Decreasing sorting \n",
    "    eb_sorted = sorted(eb.items(), key = lambda p: 1-p[1])\n",
    "    #find helper for the bottleneck\n",
    "    for i in range(5):\n",
    "        print('Betweenness value ' , eb_sorted[i][1])\n",
    "        print('Bottleneck from ', Airport_to_city.get(eb_sorted[i][0][0]), 'to', Airport_to_city.get(eb_sorted[i][0][1]))\n",
    "        \n",
    "        helper_routes = merged_routes[(merged_routes.SourceAirport == eb_sorted[i][0][0]) & (merged_routes.DestinationAirport == eb_sorted[i][0][1])]\n",
    "        if (helper_routes.shape[0] > 1):\n",
    "            print('Best helpers : ')\n",
    "            print((helper_routes[helper_routes.Name != airline].Name.to_string(index=False)))\n",
    "            print()\n",
    "        else:\n",
    "            print(airline, ' is the unique airline \\n\\n')\n",
    "            \n",
    "\n",
    "find_helper('American Airlines')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_routes['SourceCountry'] = merged_routes.apply(lambda x: \n",
    "                Airport_to_country[x.SourceAirport], axis=1)\n",
    "merged_routes['DestinationCountry'] = merged_routes.apply(lambda x: \n",
    "                Airport_to_country[x.DestinationAirport], axis=1)\n",
    "merged_routes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(route_a, route_b):\n",
    "    source_dist = distance(distance_mapping[route_a['SourceAirport']],\n",
    "                           distance_mapping[route_b['SourceAirport']]).km\n",
    "    dest_dist = distance(distance_mapping[route_a['DestinationAirport']],\n",
    "                         distance_mapping[route_b['DestinationAirport']]).km\n",
    "    return source_dist <= 100 and dest_dist <= 100\n",
    "\n",
    "\"\"\"\n",
    "Computed the overlap (competition) score between two airlines.\n",
    "It takes not only nodes into consideration but also the edges.\n",
    "So, if Airline A goes from Bucharest to Zurich and Airline B\n",
    "from Geneva to Zurich, based on this fact only, they are not\n",
    "competitors.\n",
    "\"\"\"\n",
    "def compute_overlap_score(airline_x, airline_y):\n",
    "    routes_x = merged_routes[merged_routes.Name == airline_x]\n",
    "    routes_y = merged_routes[merged_routes.Name == airline_y]\n",
    "    \n",
    "    score = 0\n",
    "    for i, row_x in routes_x.iterrows():\n",
    "        does_overlap = False\n",
    "        joined_routes = routes_y[(routes_y.SourceCountry == row_x['SourceCountry']) &\n",
    "                                 (routes_y.DestinationCountry == row_x['DestinationCountry'])]\n",
    "        for j, row_y in joined_routes.iterrows():\n",
    "            if overlaps(row_x, row_y):\n",
    "                does_overlap = True\n",
    "        if does_overlap:\n",
    "            score += 1\n",
    "    return score / len(routes_x)\n",
    "\n",
    "compute_overlap_score(\"Ryanair\", \"Wizz Air\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computed the overlap (competition) score between given airlines.\n",
    "It takes not only nodes into consideration but also the edges.\n",
    "So, if Airline A goes from Bucharest to Zurich and Airline B\n",
    "from Geneva to Zurich, based on this fact only, they are not\n",
    "competitors.\n",
    "\"\"\"\n",
    "def compute_overlap_scores(airline_list):\n",
    "    scores = []\n",
    "    for airline_a in airline_list:\n",
    "        for airline_b in airline_list:\n",
    "            scores.append([airline_a, airline_b, compute_overlap_score(airline_a, airline_b)])\n",
    "    return pd.DataFrame(scores, columns = ['AirlineA', 'AirlineB', 'Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores([\"Ryanair\", \"Wizz Air\"])\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores(Low_cost)\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores(Best_Airlines)\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores(Large_Airlines)\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores(Chinese)\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_scores = compute_overlap_scores(airlines.Name)\n",
    "sns.heatmap(overlap_scores.pivot(\"AirlineA\", \"AirlineB\", \"Score\"), cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
